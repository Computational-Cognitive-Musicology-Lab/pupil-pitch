{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09e2b66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook', font_scale=1.2)\n",
    "from pyplr import graphing, utils, preproc\n",
    "from pyplr.plr import PLR\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "from scipy.signal import butter,filtfilt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb15ec1",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2564415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_lowpass_filter(data, cutoff, fs, order):\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    # Get the filter coefficients \n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y\n",
    "def json_reader(path_to_file):\n",
    "    with open(path_to_file) as f:\n",
    "        data = f.read()\n",
    "    #print(\"Data type before reconstruction : \", type(data))\n",
    "    # reconstructing the data as a dictionary\n",
    "    js = json.loads(data)\n",
    "    #print(\"Data type after reconstruction : \", type(js))\n",
    "    #print(js)\n",
    "    return js\n",
    "def json_writer(DATA,participant_no):\n",
    "    # create json object from dictionary\n",
    "    jsonobj = json.dumps(DATA)\n",
    "    # open file for writing, \"w\" \n",
    "    save_file = str(participant_no)+\".json\"\n",
    "    f = open(save_file,\"w\")\n",
    "    # write json object to file\n",
    "    f.write(jsonobj)\n",
    "    f.close()\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116493f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08fd9652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_timeseries(path):\n",
    "        # Some useful constants\n",
    "    SAMPLE_RATE = 200\n",
    "    #DURATION = 1500\n",
    "    #ONSET_IDX = 1\n",
    "    # Columns to load\n",
    "    use_cols = ['confidence',\n",
    "                'method',\n",
    "                'pupil_timestamp',\n",
    "                'eye_id',\n",
    "                'diameter_3d',\n",
    "                'diameter']\n",
    "    # Pupil Labs recording directories / exports\n",
    "    subjects = {\n",
    "        '001': [path, '000']\n",
    "    }\n",
    "    # Empty DataFrame to store processed PIPR data\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # Loop over subjects\n",
    "    for k in subjects.keys():\n",
    "        # Get a handle on a subject\n",
    "        rec = subjects[k][0]\n",
    "        export = subjects[k][1]\n",
    "        s = utils.new_subject(\n",
    "            rec, export=export, out_dir_nm='pyplr_analysis')\n",
    "\n",
    "        # Load pupil data\n",
    "        samples = utils.load_pupil(\n",
    "            s['data_dir'], eye_id='best', method='3d', cols=use_cols)\n",
    "\n",
    "        # Pupil columns to analyse\n",
    "        pupil_cols = ['diameter_3d', 'diameter']\n",
    "        try:\n",
    "            blinks  = utils.load_blinks(s['data_dir'])\n",
    "        except:\n",
    "            continue\n",
    "    samples = preproc.mask_pupil_first_derivative(samples, threshold=4.0, mask_cols=pupil_cols)\n",
    "    try:\n",
    "        samples = preproc.mask_blinks(samples, blinks, mask_cols=['diameter_3d'])\n",
    "    except:\n",
    "        print('no blinks')\n",
    "\n",
    "                    #Mask Pupil Confidence\n",
    "    samples = preproc.mask_pupil_confidence(samples, threshold=0.75, mask_cols=pupil_cols)\n",
    "    \n",
    "\n",
    "                    #Low Pass Filter the Samples at a 1 Hz Cut off\n",
    "                    #try:\n",
    "                        #Interpolate Samples \n",
    "    samples = preproc.interpolate_pupil(samples, method='nearest', order=2,interp_cols=pupil_cols)\n",
    "    samples = preproc.butterworth_series(samples, fields=pupil_cols, filt_order=3,cutoff_freq=1/(200/2))\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4a4cc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pupil_extract(path,participant_no):\n",
    "    count = 0\n",
    "    experimentsrc_data =  json_reader('/Users/noelalben/github/pupil-pitch/Pupil-labs/compare_data.txt')\n",
    "    participant_data= json_reader('/Users/noelalben/github/pupil-pitch/Pupil-labs/DATA.txt')\n",
    "    frequencies = ['820','826','832','838','844','850','856','862','868','874','880']\n",
    "    block_keys = ['block_1', 'block_2', 'block_3', 'block_4', 'block_5']\n",
    "    user_dictionary = {}\n",
    "    for i in frequencies:\n",
    "        user_dictionary[i] = {}\n",
    "        for j in block_keys:\n",
    "            user_dictionary[i][j] = {}\n",
    "            user_dictionary[i][j]['time_stamps']=[]\n",
    "            user_dictionary[i][j]['event_stamps']=[]\n",
    "            user_dictionary[i][j]['first_set']=[]\n",
    "            user_dictionary[i][j]['second_set']=[]\n",
    "            user_dictionary[i][j]['first_set_timestamps']=[]\n",
    "            user_dictionary[i][j]['second_set_timestamps']=[]\n",
    "            user_dictionary[i][j]['setup_to_next_trial'] = []\n",
    "    trial_keys = ['trial_1', 'trial_2', 'trial_3', 'trial_4', 'trial_5']\n",
    "    # Some useful constants\n",
    "    SAMPLE_RATE = 200\n",
    "    #DURATION = 1500\n",
    "    #ONSET_IDX = 1\n",
    "    # Columns to load\n",
    "    use_cols = ['confidence',\n",
    "            'method',\n",
    "            'pupil_timestamp',\n",
    "            'eye_id',\n",
    "            'diameter_3d',\n",
    "            'diameter']\n",
    "    participant_info = experimentsrc_data[str(participant_no)]\n",
    "    for block in range(1,6):\n",
    "        block_folder = str(participant_no)+str(block)\n",
    "        if(participant_no >= 10):\n",
    "                block_folder = '0'+str(participant_no)+str(block)\n",
    "                print(block_folder)\n",
    "                flag = True\n",
    "        else:\n",
    "            flag = False\n",
    "        freqs = []\n",
    "        for trial_number in range(0,11):\n",
    "            freq = participant_info[trial_keys[block-1]]['Stimuli'][trial_number][6:9]\n",
    "            freqs.append(freq)\n",
    "            print(freqs)\n",
    "            user_block = user_dictionary[freq][block_keys[block-1]]\n",
    "            \n",
    "            #print(user_block)\n",
    "            trial_folder = '00'+str(trial_number)\n",
    "            if(trial_number == 10):\n",
    "                trial_folder = '010'\n",
    "            directory = path+'/00'+block_folder+'/'+trial_folder\n",
    "            if(flag==True):\n",
    "                directory = path+'/'+block_folder+'/'+trial_folder\n",
    "            print(directory)\n",
    "            # Pupil Labs recording directories / exports\n",
    "            subjects = {\n",
    "            '001': [directory, '000']\n",
    "            }\n",
    "            df = pd.DataFrame()\n",
    "\n",
    "            # Loop over subjects\n",
    "            for k in subjects.keys():\n",
    "                # Get a handle on a subject\n",
    "                rec = subjects[k][0]\n",
    "                export = subjects[k][1]\n",
    "                s = utils.new_subject(\n",
    "                    rec, export=export, out_dir_nm='pyplr_analysis')\n",
    "\n",
    "                # Load pupil data\n",
    "                samples = utils.load_pupil(\n",
    "                    s['data_dir'], eye_id='best', method='3d', cols=use_cols)\n",
    "                blinks  = utils.load_blinks(s['data_dir'])\n",
    "\n",
    "                # Pupil columns to analyse\n",
    "                pupil_cols = ['diameter_3d', 'diameter']\n",
    "\n",
    "                #First Derivative\n",
    "                samples = preproc.mask_pupil_first_derivative(samples, threshold=3.0, mask_cols=pupil_cols)\n",
    "                \n",
    "                try:\n",
    "                    #Mask Blinks \n",
    "                    samples = preproc.mask_blinks(samples, blinks, mask_cols=['diameter_3d'])\n",
    "\n",
    "                    #Mask Pupil Confidence\n",
    "                    samples = preproc.mask_pupil_confidence(samples, threshold=0.75, mask_cols=pupil_cols)\n",
    "\n",
    "\n",
    "                    #Low Pass Filter the Samples at a 1 Hz Cut off\n",
    "                    #try:\n",
    "                        #Interpolate Samples \n",
    "\n",
    "                    samples = preproc.interpolate_pupil(samples, method='nearest', order=2,interp_cols=pupil_cols)\n",
    "                    samplestmp = samples\n",
    "                    samples1 = preproc.butterworth_series(samplestmp, fields=pupil_cols, filt_order=3,cutoff_freq=1/(200/2))\n",
    "                    if (samples1['diameter_3d'].isnull().all() == True):\n",
    "                        samples = samples\n",
    "                    else:\n",
    "                        samples = samples1\n",
    "                   # except samples['diameter_3d'].isnull().all() == True:\n",
    "                except Exception:\n",
    "                                        #Mask Pupil Confidence\n",
    "                    samples = preproc.mask_pupil_confidence(samples, threshold=0.75, mask_cols=pupil_cols)\n",
    "\n",
    "\n",
    "                    #Low Pass Filter the Samples at a 1 Hz Cut off\n",
    "                    #try:\n",
    "                        #Interpolate Samples \n",
    "\n",
    "                    samples = preproc.interpolate_pupil(samples, method='nearest', order=2,interp_cols=pupil_cols)\n",
    "                    samplestmp = samples\n",
    "                    samples1 = preproc.butterworth_series(samplestmp, fields=pupil_cols, filt_order=3,cutoff_freq=1/(200/2))\n",
    "                    if (samples1['diameter_3d'].isnull().all() == True):\n",
    "                        samples = samples\n",
    "                    else:\n",
    "                        samples = samples1\n",
    "                   # except samples['diameter_3d'].isnull().all() == True:\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "\n",
    "                events = utils.load_annotations(s['data_dir'])\n",
    "                event_qeury = events.axes[0].tolist()\n",
    "                event_qeury = [round(float(i), 2) for i in event_qeury]\n",
    "                qeury = samples.axes[0].tolist()\n",
    "                query = [round(float(i), 2) for i in qeury ]\n",
    "                user_block['time_stamps'] = query\n",
    "                user_block['event_stamps'] = event_qeury\n",
    "                \n",
    "                interpolation = np.size(np.where(samples['interpolated']==1)[0])\n",
    "                all_values =  np.size(samples['interpolated'])\n",
    "                percs = interpolation/all_values\n",
    "                if(percs>0.8):\n",
    "                    user_block['first_set'] = 'Reject'\n",
    "                    user_block['second_set'] = 'Reject'\n",
    "                    count = count+1\n",
    "                    print('------here--------')\n",
    "                    continue\n",
    "\n",
    "                #Plotting the samples for participant\n",
    "                #First two Events \n",
    "                try:\n",
    "                    samples_extract = samples.iloc[query.index(event_qeury[0]):query.index(event_qeury[1])+600,:].iloc[::50,:].axes[0].tolist()\n",
    "                    user_block['first_set_timestamps'] = samples_extract\n",
    "                    user_block['untilevent0'] =samples.iloc[0:query.index(event_qeury[0]),:]['diameter_3d'].tolist()\n",
    "                    user_block['first_set'] = samples.iloc[query.index(event_qeury[0]):query.index(event_qeury[1])+600,:].iloc[::50,:]['diameter_3d'].tolist()\n",
    "                    if trial_number>0:\n",
    "                        print(trial_number)\n",
    "                        user_block_prev = user_dictionary[freqs[trial_number-1]][block_keys[block-1]]\n",
    "                        setup = user_block_prev['setup_to_next_trial']\n",
    "                        if(user_block_prev['first_set'] != 'Reject'):\n",
    "                            setup = setup[len(setup) - 1::-1][0:12]\n",
    "                            setup = setup[len(setup) - 1::-1]\n",
    "                            user_block['first_set'][:0] = setup[0:12]\n",
    "\n",
    "               # Second set of Events\n",
    "                    samples_extract2 = samples.iloc[query.index(event_qeury[2]):query.index(event_qeury[4])+800,:].iloc[::50,:].axes[0].tolist()\n",
    "                    user_block['second_set_timestamps']=samples_extract2\n",
    "                    \n",
    "                    user_block['second_set'] = samples.iloc[query.index(event_qeury[2]):query.index(event_qeury[4])+800,:].iloc[::50,:]['diameter_3d'].tolist()\n",
    "             # Anticipation of new block\n",
    "                    samples_extract3 = samples.iloc[query.index(event_qeury[4])+200:,:].iloc[::50,:]['diameter_3d'].tolist()\n",
    "                    user_block['setup_to_next_trial'] = samples_extract3\n",
    "                    \n",
    "                except Exception:\n",
    "                    continue\n",
    "                \n",
    "    json_writer(user_dictionary,participant_no)\n",
    "    \n",
    "    return user_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553595a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Answer_check(Comparison_Hz, Block_number,participantsrc_data,participant_respond_data):\n",
    "    Trials = ['trial_1','trial_2','trial_3','trial_4','trial_5']\n",
    "    comparison_flag = 'rshift'\n",
    "    if (Comparison_Hz<850):\n",
    "        comparison_flag = 'lshift'\n",
    "    \n",
    "    participant_data = participantsrc_data[Trials[Block_number-1]]\n",
    "    participant_data_stimuli = np.asarray(participant_data['Stimuli'])\n",
    "    checker = 'Audio/'+str(Comparison_Hz)+'.0.wav'\n",
    "    print(checker)\n",
    "    find = np.where(checker == participant_data_stimuli)[0]\n",
    "    participant_response_data = participant_respond_data[Trials[Block_number-1]]\n",
    "    print(participant_response_data)\n",
    "    print(participant_data['Answers'])\n",
    "    print(find)\n",
    "    if(participant_response_data[0][find[0]] == participant_data['Answers'][find[0]]):\n",
    "        Answer = 'Correct'\n",
    "    elif (Comparison_Hz == 850):\n",
    "        Answer = 'Correct'\n",
    "    else:\n",
    "        Answer = 'Incorrect'\n",
    "    return Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc81af70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b532c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/noelalben/Desktop/Pupil-PitchData/EyeRecording'\n",
    "dics = []\n",
    "for i in range(3,15):\n",
    "    dics.append(pupil_extract(path,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7878e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/noelalben/Desktop/Pupil-PitchData/EyeRecording'\n",
    "dic_5 = pupil_extract(path,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da65a434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd9dfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [pd.DataFrame(columns=['Participant','Comparison Hertz','3s-pre-ready','2s-pre-ready','1s-pre-ready','0th-time','at-ready','1s-post-ready','2s-post-ready','at-standard','1s-post-standard','2s-post-standard','3s-post-standard','at-comparison','1s-post-comparison','2s-post-comp','3s-post-comp','at-response','1s-post-response','2s-post-response','3s-post-response','4s-post-response','Response (Correct/Incorrect)','Baseline'],index = indexes) for x in range(11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd1f821",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "for df_iter in df_list:\n",
    "    #df_iter = pd.DataFrame(columns=['Participant','Comparison Hertz','3s-pre-ready','2s-pre-ready','1s-pre-ready','at-ready','1s-post-ready','2s-post-ready','at-standard','1s-post-standard','2s-post-standard','3s-post-standard','at-comparison','1s-post-comparison','2s-post-comp','3s-post-comp','at-response','1s-post-response','2s-post-response','3s-post-response','4s-post-response','Response (Correct/Incorrect)'],index = indexes)\n",
    "    path = '/Users/noelalben/github/pupil-pitch/'\n",
    "    freq_in_check =int(frequencies[k])\n",
    "    k = k+1\n",
    "    for i in range(3,15):\n",
    "        read_path = path + str(i)+'.json'\n",
    "        user_dictionary = json_reader(read_path)\n",
    "        for j in range(1,6):\n",
    "            user_block_first_set = user_dictionary[str(freq_in_check)][block_keys[j-1]]['first_set']\n",
    "            user_block_second_set = user_dictionary[str(freq_in_check)][block_keys[j-1]]['second_set']\n",
    "            Answer = Answer_check(freq_in_check, j-1,experimentsrc_data[str(i)],participant_data[str(i)][str(i)]['Key_Responds'])\n",
    "            try:\n",
    "                user_block_begining = np.mean(user_dictionary[str(freq_in_check)][block_keys[j-1]]['untilevent0'][0:-10])\n",
    "            except:\n",
    "                user_block_begining = []\n",
    "            participant_block = str(i)+'_'+str(j)\n",
    "            print(participant_block)\n",
    "            try:\n",
    "                if(len(user_block_first_set)<20):\n",
    "                    df_iter.loc[participant_block] = pd.Series({'Participant':i,'Comparison Hertz':freq_in_check,'0th-time': user_block_begining, 'at-ready':user_block_first_set[2],'1s-post-ready':user_block_first_set[6],'2s-post-ready':user_block_first_set[10],'at-standard':user_block_second_set[0],'1s-post-standard':user_block_second_set[4],'2s-post-standard':user_block_second_set[8],'3s-post-standard':user_block_second_set[12],'at-comparison':user_block_second_set[16],'1s-post-comparison':user_block_second_set[20],'2s-post-comp':user_block_second_set[24],'3s-post-comp':user_block_second_set[28],'at-response':user_block_second_set[32],'1s-post-response':user_block_second_set[36],'2s-post-response':user_block_second_set[40],'3s-post-response':user_block_second_set[44],'4s-post-response':user_block_second_set[47],'Response (Correct/Incorrect)':Answer,'Baseline':user_block_begining})\n",
    "                else:   \n",
    "                    df_iter.loc[participant_block] = pd.Series({'Participant':i,'Comparison Hertz':freq_in_check,'3s-pre-ready':user_block_first_set[0],'2s-pre-ready':user_block_first_set[4],'1s-pre-ready':user_block_first_set[8],'at-ready':user_block_first_set[2+12],'1s-post-ready':user_block_first_set[6+12],'2s-post-ready':user_block_first_set[10+12],'at-standard':user_block_second_set[0],'1s-post-standard':user_block_second_set[4],'2s-post-standard':user_block_second_set[8],'3s-post-standard':user_block_second_set[12],'at-comparison':user_block_second_set[16],'1s-post-comparison':user_block_second_set[20],'2s-post-comp':user_block_second_set[24],'3s-post-comp':user_block_second_set[28],'at-response':user_block_second_set[32],'1s-post-response':user_block_second_set[36],'2s-post-response':user_block_second_set[40],'3s-post-response':user_block_second_set[44],'4s-post-response':user_block_second_set[47],'Response (Correct/Incorrect)':Answer,'Baseline':np.mean(user_block_first_set[0:8:4])})\n",
    "            except:\n",
    "                df_iter.loc[participant_block] = pd.Series({'Participant':i, 'Comparison Hertz':freq_in_check, '3s-pre-ready': 'REJECT'})\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7026f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Baseline\n",
    "frequencies = ['820','826','832','838','844','850','856','862','868','874','880']\n",
    "path = '/Users/noelalben/github/pupil-pitch/'\n",
    "c= 0\n",
    "baselines ={}\n",
    "for k in range(3,15):\n",
    "    baselines[k] = {}\n",
    "for k in range(3,15):\n",
    "    read_path = path + str(k)+'.json'\n",
    "    user_dictionary = json_reader(read_path)\n",
    "    for j in range(1,6):\n",
    "        baseline = []\n",
    "        for i in range(0,11):\n",
    "            freq_in_check =int(frequencies[i])\n",
    "            user_block_first_set = user_dictionary[str(freq_in_check)][block_keys[j-1]]['first_set']\n",
    "            if(len(user_block_first_set)>20):\n",
    "                baseline.append(user_block_first_set[0:12])\n",
    "            else:\n",
    "                print('here')\n",
    "                c = c+1\n",
    "                print(c)\n",
    "        flat_list = [item for sublist in baseline for item in sublist]\n",
    "        \n",
    "        baselines[k][j] = sum(flat_list)/len(flat_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0497dd6",
   "metadata": {},
   "source": [
    "## Variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006ff757",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_s = [df_820,df_826,df_832,df_838,df_844,df_850,df_856,df_862,df_868,df_874,df_880]\n",
    "frequencies = ['820','826','832','838','844','850','856','862','868','874','880']\n",
    "indexes = ['4_1','4_2','4_3','5_1','5_2','5_3','6_1','6_2','6_3','7_1','7_2','7_3','8_1','8_2','8_3','9_1','9_2','9_3','11_1','11_2','11_3','12_1','12_2','12_3','13_1','13_2','13_3','14_1','14_2','14_3','16_1','16_2','16_3','17_1','17_2','17_3']\n",
    "frequencies = ['820','826','832','838','844','850','856','862','868','874','880']\n",
    "\n",
    "indexes = ['4_1','4_2','4_3','5_1','5_2','5_3','6_1','6_2','6_3','7_1','7_2','7_3','8_1','8_2','8_3','9_1','9_2','9_3','11_1','11_2','11_3','12_1','12_2','12_3','13_1','13_2','13_3','14_1','14_2','14_3']\n",
    "df_880= pd.DataFrame(columns=['Participant','Comparison Hertz','3s-pre-ready','2s-pre-ready','1s-pre-ready','at-ready','1s-post-ready','2s-post-ready','at-standard','1s-post-standard','2s-post-standard','3s-post-standard','at-comparison','1s-post-comparison','2s-post-comp','3s-post-comp','at-response','1s-post-response','2s-post-response','3s-post-response','4s-post-response','Response (Correct/Incorrect)'],index = indexes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dab9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Answer_check(Comparison_Hz, Block_number,participantsrc_data,participant_respond_data):\n",
    "    Trials = ['trial_1','trial_2','trial_3']\n",
    "    comparison_flag = 'rshift'\n",
    "    if (Comparison_Hz<850):\n",
    "        comparison_flag = 'lshift'\n",
    "    \n",
    "    participant_data = participantsrc_data[Trials[Block_number-1]]\n",
    "    participant_data_stimuli = np.asarray(participant_data['Stimuli'])\n",
    "    checker = 'Audio/'+str(Comparison_Hz)+'.0.wav'\n",
    "    print(checker)\n",
    "    find = np.where(checker == participant_data_stimuli)[0]\n",
    "    participant_response_data = participant_respond_data[Trials[Block_number-1]]\n",
    "    print(participant_response_data)\n",
    "    print(participant_data['Answers'])\n",
    "    print(find)\n",
    "    if(participant_response_data[0][find[0]] == participant_data['Answers'][find[0]]):\n",
    "        Answer = 'Correct'\n",
    "    elif (Comparison_Hz == 850):\n",
    "        Answer = 'Correct'\n",
    "    else:\n",
    "        Answer = 'Incorrect'\n",
    "    return Answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
